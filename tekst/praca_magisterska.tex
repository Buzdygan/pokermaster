\documentclass[licencjacka]{pracamgr}

\usepackage{polski}
\usepackage{algpseudocode}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
%\usepackage{float}
\usepackage{wrapfig}
\usepackage{hyperref}
\usepackage{placeins}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{setspace}

\singlespacing

\newtheorem{theorem}{Twierdzenie}[chapter]
\newtheorem{lemma}[theorem]{Lemat}
\newtheorem{proposition}[theorem]{Stwierdzenie}
\newtheorem{corollary}[theorem]{Wniosek}
\newtheorem{definition}[theorem]{Definicja}

\newenvironment{proof}[1][Dowód]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Przykład]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Uwaga]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\qed}{\nobreak \ifvmode \relax \else
        \ifdim\lastskip<1.5em \hskip-\lastskip
            \hskip1.5em plus0em minus0.5em \fi \nobreak
                  \vrule height0.75em width0.5em depth0.25em\fi}

\allowdisplaybreaks


%\floatstyle{boxed}
%\restylefloat{figure}
%\floatplacement{figure}{H}

\author{Jakub Tlałka}
\nralbumu{292665}

\title{Heurystyczna modyfikacja techniki CFR w Pokerze}
\tytulang{Heuristic modification of CFR technique in Poker}

\kierunek{Informatyka}

\opiekun{dra Jakuba Pawlewicza\\
  Wydzia{\l} Matematyki Informatyki i Mechaniki\\
  }
  
\date{Sierpień 2014}

%TODO poprawić numerek
\dziedzina{
11.3 Informatyka\\
}

%TODO zmienić klasyfikacjż
\klasyfikacja{D. Maths\\
D.0. General\\}

%TODO uzupełnić sżowa kluczowe
\keywords{}
 
\newtheorem{defi}{Definicja}[section]

\begin{document}
\maketitle

\begin{abstract}
\end{abstract}

\tableofcontents

\chapter{Wstęp}

\chapter{Wprowadzenie do Pokera}

\section{Pomocnicze pojęcia}

\begin{itemize}
\item Stan gry jest opisany przez zespół informacji, które są rezultatem dotychczasowych akcji
      podjętych przez graczy oraz zdarzeń losowych. Stan gry jednoznacznie definiuje zbiór dostępnych
      akcji oraz graczy, którzy je wykonują (wliczając w to tzw gracza losowego, który odpowiada
      za generowanie zdarzeń losowych zgodnie z zasadami gry). Wykonywane przez graczy akcje
      zmieniają stan gry (inaczej ich wykonywanie nie ma sensu).
\item Graf gry to graf, którego wierzchołkami są stany gry a krawędź prowadzi od stanu
      $s_1$ do stanu $s_2$ jeśli w stanie $s_1$ można wykonać akcję prowadzącą do stanu
      $s_2$. W większości gier graf ten nie zawiera cyklu dlatego zazwyczaj nazywa się go
      drzewem gry.
\item Gra z pełną/niepełną informacją. Nie wszystkie informacje składające się na stan gry
      są dostępne wszystkim graczom. Np w grach karcianych karty które posiada przeciwnik
      są zazwyczaj niewidoczne dla gracza. Takie gry nazywa się grami z niepełną informacją.
      Jeśli wszystkie informacje są dostępne wszystkim graczom, jest to gra z pełną informacją.
      Przykładem takiej gry są szachy.
\item Zbiór informacyjny dla gracza $p$ zawiera te stany gry, które są identyczne jeśli chodzi
      o informacje dostępne graczowi $p$. Przykładowo, w dwuosobowej grze karcianej, przykładem zbioru informacyjnego
      jest zbiór wszystkich stanów zaraz po rozdaniu kart, w których gracz $p$ ma na ręku jedynie asa i króla kier.
      Zbiory informacyjne są ważne z punktu widzenia podejmowania decyzji: w każdym stanie gry należącym do tego
      samego zbioru informacyjnego gracza $p$, gracz $p$ podejmuje decyzje wg tej samej strategii.
\item Strategia gracza $p$ wyznacza zasady podejmowania przez gracza akcji w zbiorach informacyjnych.
      Strategia może być deterministyczna, jeśli w każdym zbiorze informacyjnym jest wyznaczona dokładnie
      jedna podejmowana akcja, bądź mieszana jeśli na akcjach określony jest rozkład prawdopodobieństwa
      zagrania ich.
\item Programy, które podejmują akcje w grze zgodnie z zaprogramowaną bądź wyliczoną strategią nazywamy botami
\end{itemize}

\section{Sztuczna inteligencja w grach}

Sztuczna inteligencja w grach to dział algorytmiki zajmujący się badaniem programów grających
z dużą skutecznością w gry. Jest dużo rodzajów gier. Gry jednoosobowe to tzw łamigłówki, w których
należy znaleźć odpowiednią sekwencję ruchów, prowadzącą do jak najlepszego wyniku. Algorytmy znajdujące
takie sekwencje opierają się na efektywnym przeglądaniu drzewa gry. Programy grające w gry wieloosobowe
muszą wyliczyć odpowiednią strategię. Gry różnią się złożonością informacji składających się na stan gry.
Nawet prosta gra, w której graczom przydzielana jest losowo wybrana liczba rzeczywista, mają nieskończenie
wiele stanów gry. Zazwyczaj jednak informacje można reprezentować przez ograniczone liczby całkowite przez co
liczba stanów gry też jest ograniczona. Przedmiotem badań tej pracy jest gra Texas Holdem Poker, która
należy do gatunku gier z niepełną informacją z ograniczoną liczbą stanów gry.

\section{Texas Holdem Poker}

Texas Holdem Poker to gra karciana przeznaczona dla co najmniej dwóch graczy. Na początku pojedynczej rozgrywki każdy z graczy
dostaje dokładnie dwie karty, których nie pokazuje przeciwnikom. Następuje potem runda licytacji, w której
gracze ustalają wysokość stawki. W pierwszej rundzie licytacji gracz zaczynający musi wejść do gry
za stawkę ustaloną wielkością "small blind" a następny gracz w kolejności musi wejść stawką o wysokości
"big blind". \\

\noindent
W licytacji gracze odzywają się w ustalonej kolejności. Mogą wejść za całą dostępną im kwotę (all-in), podbić stawkę (raise), pozostać przy
obecnej stawce (call) lub zrezygnować z udziału w licytacji (fold). W pierwszych dwóch przypadkach są
zobowiązani oddać do puli stawkę na jaką się zgodzili. Różne wersje gry określają ograniczenia podnoszenia
stawki. W tej pracy przyjęta jest wersja, w której można podnieść stawkę o dowolną kwotę całkowitą o ile stawka
po podniesieniu nie przekracza 128 jednostek. Popularną ale jednocześnie trudną obliczeniowo wersją
jest wersja no-limit, w której nie nakłada się limitu na kwotę przebicia.
Stawka na zakończenie licytacji zostaje ustalona, gdy
wszyscy gracze biorący jeszcze udział w licytacji zaakceptują aktualną wysokość stawki. Jeśli będzie to
tylko jedna osoba, zostaje ona zwycięzcą i zgarnia całą pulę a gra się kończy. W limit Texas Holdem Poker
nakłada się ograniczenie na liczbę zagrywek jednego gracza w licytacji.\\

\noindent
Po pierwszej rundzie licytacji następuje wyłożenie trzech kart na stół, tak by widzieli je wszyscy gracze.
Jest to tzw "flop". Następuje kolejna runda licytacji po czym wykładana jest jedna karta, tzw "turn".
Po trzeciej rundzie licytacji na stół wykładana jest ostatnia karta "river" i następuje ostatnia runda
licytacji. Jeżeli w ostatniej rundzie co najmniej dwóch graczy uzgodni ostateczną stawkę gry, następuje
wyłożenie kart graczy na stół i rozstrzygnięcie kto został zwycięzcą. \\

\noindent
Zwycięzcą zostaje gracz, który jest w stanie wybrać ze swoich kart oraz kart na stole, najsilniejszy
5-kartowy układ. Siłę układu 5 kart wyznacza poniższy ranking, dla każdego typu układu, im wyższe
figury występują w układzie tym większa jest jego siła. Typy układów wymienione są w kolejności
od najsilniejszego do najsłabszego.

\begin{enumerate}
\item \textbf{Poker}: 5 kolejnych kart w tym samym kolorze, np $(D\clubsuit, W\clubsuit, 10\clubsuit, 9\clubsuit, 8\clubsuit)$ 
\item \textbf{Kareta}: 4 takie same figury, np $(7\heartsuit, 7\spadesuit, 7\diamondsuit, 7\clubsuit, D\diamondsuit)$
\item \textbf{Full}: Trójka takich samych figur połączona z parą takich samych figur, np $(K\heartsuit, K\diamondsuit, K\clubsuit, 3\heartsuit, 3\diamondsuit)$ 
\item \textbf{Kolor}: 5 kart w tym samym kolorze, np $(K\diamondsuit, W\diamondsuit, 6\diamondsuit, 5\diamondsuit, 2\diamondsuit)$
\item \textbf{Strit}: 5 kolejnych kart, np $(10\heartsuit, 9\diamondsuit, 8\heartsuit, 7\clubsuit, 6\spadesuit)$
\item \textbf{Trójka}: 3 takie same figury, np $(5\heartsuit, 5\diamondsuit, 5\clubsuit, 8\heartsuit, D\spadesuit)$
\item \textbf{Dwie pary}: Dwie pary tych samych figur, np $(A\heartsuit, A\diamondsuit, 8\clubsuit, 8\heartsuit, W\clubsuit)$
\item \textbf{Para}: Para tych samych figur, np $(10\clubsuit, 10\spadesuit, A\heartsuit, 9\clubsuit, 2\heartsuit)$
\item \textbf{Najwyższa karta}: Najwyższa figura, np $(K\heartsuit, W\diamondsuit, 10\heartsuit, 9\heartsuit, 5\spadesuit)$
\end{enumerate}

\noindent
W sytuacji gdy gracze mają ten sam typ układu, z tymi samymi figurami, pod uwagę brane są pozostałe karty z układu. Np
układ $(7\heartsuit, 7\diamondsuit, 7\clubsuit, K\heartsuit, W\clubsuit)$ jest silniejszy od układu
$(7\spadesuit, 7\diamondsuit, 7\clubsuit, K\spadesuit, 5\diamondsuit)$. \\

\noindent
Jeśli po uwzględnieniu wszystkich 5 kart układu nadal występuje remis (np gdy najsilniejszy układ stanowią karty na stole),
pula jest dzielona między graczy z najwyższym układem.

\section{Rozwój botów grających w Pokera}

Pierwsze boty opierały swoją strategię na zbiorze zasad wpisanych ręcznie przez pokerowych graczy. Zasady określały
sposób podejmowania decyzji w konkretnych sytuacjach, np "mając na ręku Asa i Damę" podbijaj stawkę trzykrotnie".
W 2004 roku powstał program WinHoldem, który umożliwiał proste tworzyenie botów grających według pewnego zbioru zasad.
Jednocześnie, w środowiskach akademickich rozwijały się podejścia oparte na znajdowaniu równowagi Nasha. Owocem tych
badań jest między innymi opisywany w tej pracy algorytm CFR. Takie podejścia przeważają w długiej serii rozgrywek ale
brakuje im umiejętności wykorzystania słabości w strategiach przeciwnika. Powstały również algorytmy, które w serii
rozgrywek próbują estymować strategię przeciwnika i znajdują najlepszą dla niej kontrstrategię. \cite{exploit}

\section{Zmniejszanie drzewa gry}

Drzewo gry w pokerze jest bardzo duże. W dwuosobowym no-limit Texas Holdem Poker jest wielkości
ok. $10^{70}$ stanów. \cite{monte-carlo}. Dlatego niezbędne jest wprowadzenie abstrakcji gry.
Pierwsze ograniczenie, które zastosowano dotyczy licytacji. Dostępne są maksymalnie 4 akcje:
fold (rezygnacja z licytacji), call (pozostanie przy obecnej stawce), raise(dwukrotne podbicie stawki) oraz
all in(zalicytowanie maksymalnej stawki - 128). W ten sposób jedyne możliwe wysokości stawek w licytacji to: $1$, $2$,
$4$, $8$, $16$, $32$, $64$ i $128$. \\\\
\noindent
Drugie ograniczenie przyporządkowuje układom kart graczy (karty na ręce wraz z kartami na stole) tzw "koszyki".
W jednym "koszyku" są karty o podobnej sile. W każdej rundzie licytacji obowiązuje osobny podział, zmienna
jest też liczba koszyków. Testowano różne liczby koszyków, w zależności od używanego algorytmu. \\\\
\noindent
Do oceny siły układów zastosowano miarę "Effective Hand Strength" (EHS). EHS układu wyliczany
jest z trzech innych miar: "Hand Strength" ($HS$), "Positive Potential" ($Ppot$) oraz "Negative Potential" ($Npot$) według
wzoru:

\begin{align*}
EHS = HS \cdot (1 - Npot) + (1 - HS) \cdot Ppot
\end{align*}

\noindent
$HS$ to w przybliżeniu prawdopodobieństwo że nasza ręka jest lepsza od ręki przeciwnika. Miary $Ppot$ i $Npot$ oznaczają
prawdopodobieństwo że nasza ręka stanie się lepsza (odpowiednio gorsza) od ręki przeciwnika po wyłożeniu kolejnych kart na stół. \\



\chapter{Metoda CFR}

Metoda CFR (Counterfactual Regret Minimization) to algorytm, który pozwala znajdować równowagę Nasha
w grach w postaci ekstensywnej. Jest to obecnie najlepsze rozwiązanie w dziedzinie badań nad
sztuczną inteligencją w Pokerze. Choć używane są głównie różne modyfikacje algorytmu, chciałbym
przedstawić tu jego bazową wersję.

\section{Terminologia}

\begin{itemize}

\item Zbiór graczy oznaczamy przez $N$.
\item Zbiór wszystkich możliwych ciągów akcji (historii) legalnych w grze nazywamy $H$. Ciągi, po których kończy
      się rozgrywka, należą do podzbioru $Z$. Oczywiście każdej historii jest przyporządkowany stan gry, który
      jest jej efektem.
\item Dla każdej historii $h$ zbiór akcji dostępnych w stanie gry jej odpowiadającym oznaczamy przez $A(h)$. Oczywiście
      każdy stan wyznacza jednoznacznie gracza wykonującego akcje.
\item Dla każdego gracza $i$, zbiór historii, w których ma on ruch, są pogrupowane w tzw zbiory informacyjne $I_i$. Dla zbioru
      informacyjnego $I_i$ oraz dowolnych dwóch historii $h_1, h_2 \in I_i$ zachodzi $A(h_1) = A(h_2) = A(I_i)$. Do jednego
      zbioru informacyjnego $I_i$ należą historie, które są parami tożsame po usunięciu z nich akcji niewidocznych dla gracza $i$
      (np w Pokerze są to akcje przydzielenia kart prywatnych graczom innym niż $i$).
\item Gracza losowego oznaczamy przez $c$. Funkcja $f_c(h, a)$ oznacza prawdopodobieństwo zaistnienia akcji $a$ dla historii $h$.
\item Strategię gracza $i$ oznaczamy przez $\sigma_i$. $\sigma_i(I_i, a)$ oznacza prawdopodobieństwo wykonania akcji $a$ przez
      gracza $i$ w zbiorze informacyjnym $I_i$ jeśli gra on strategią $\sigma_i$. Przyjmujemy $\sigma_c(h, a) = f_c(h, a)$.
      Przez $\sigma$ oznaczamy zespół strategii wszystkich graczy biorących udział w rozgrywce. Przez $\sigma_{-i}$ oznaczamy
      zespół strategii wszystkich graczy z wyjątkiem $i$.
\item Przez $\pi^{\sigma}(h)$ oznaczamy prawdopodobieństwo zajścia historii $h$ dla zespołu strategii $\sigma$.
      $\pi^{\sigma}(I)$ to suma tych prawdopodobieństw po $h \in I$. $\pi_i^{\sigma}(h)$ to prawdopodobieństwo że grając
      zgodnie ze strategią $\sigma$, gracz $i$ będzie podejmował akcje z odpowiadającej historii $h$. Analogicznie
      $\pi_{-i}^{\sigma}(h)$ oznacza prawdopodobieństwo że pozostali gracze będą podejmowali akcje z historii $h$.
\item Dla końcowych historii $h \in Z$ określamy funkcję użyteczności $u_i(h)$ oznaczającą zysk gracza $i$ w rozgrywce
      określonej przez $h$.

\end{itemize}

\noindent
W dalszej części będziemy zajmować się grami dwuosobowymi, przede wszystkim dwuosobową wersją Texas Holdem Poker.

\section{$\epsilon$-równowaga Nasha}

$\epsilon$-równowagą Nasha nazywamy zespół strategii $\sigma$, taki że:

\begin{align*}
u_1(\sigma) + \epsilon \geq  \max_{\sigma_1'} \, u_1(\sigma_1', \sigma_2) 
\end{align*}

\begin{align*}
u_2(\sigma) + \epsilon \geq  \max_{\sigma_2'} \, u_2(\sigma_1, \sigma_2') 
\end{align*}

\noindent
Metoda CFR znajduje $\epsilon$-równowagę Nasha dla $\epsilon$ malejącego proporcjonalnie do pierwiastka z liczby iteracji.

\section{Minimalizacja funkcji regretu}

W dalszej części przyjmujemy że rozgrywane są kolejne rundy indeksowane przez $t$. W każdej z rund
strategie graczy będą modyfikowane na podstawie dotychczasowej rozgrywki, w efekcie dając ciąg strategii
$(\sigma^t)$. Jako uśrednioną strategię gracza $i$ po $T$ rundach definiujemy:

\begin{align*}
\overline{\sigma}_i^T(I, a) = \frac{\sum\limits_{t=1}^T \pi_i^{\sigma^t}(I) \, \sigma^t(I, a)}{\sum\limits_{t=1}^T \, \pi_i^{\sigma^t}(I)}
\end{align*}

\noindent
Intuicyjnie funkcja regretu określa ile gracz mógłby zyskać zamieniając obecną strategię na najlepszą możliwą
przy założeniu że inni gracze pozostali by przy obecnych strategiach. Formalnie definiujemy średni całkowity regret gracza $i$
w rozgrywce o numerze $T$ przez:

\begin{align*}
R_i^T = \frac{1}{T} \, \max_{\sigma_i'} \sum\limits_{t=1}^T \, (u_i(\sigma_i', \sigma_{-i}^t) - u_i(\sigma^t))
\end{align*}

%todo dodaj referencje
\noindent
Znany wynik (referencja) mówi o tym, że w grze o sumie zerowej, jeśli po $T$ iteracjach średni całkowity regret obu graczy
jest mniejszy niż $\epsilon$ to uśredniony zespół strategii $\overline{\sigma}^T$ jest $2\epsilon$-równowagą Nasha.

\section{Funkcja regretu lokalnego}

By łatwiej minimalizować regret całkowity, wprowadzamy funkcję regretu lokalnego.
Działa ona na podobnej zasadzie co regret całkowity, ale jest określana na zbiorach informacyjnych
a nie na całej grze. Dzięki temu można ją minimalizować osobno dla każdego zbioru informacyjnego. \\\\

\noindent
Niech $\sigma_{|I \rightarrow a}$ oznacza strategię $\sigma$ zmodyfikowaną tak, że w zbiorze informacyjnym $I$ zawsze
wykonywana jest akcja $a$. $u_i(\sigma, I)$ oznacza warunkową wartość oczekiwaną zysku gracza $i$ przy założeniu że
osiągnięty został zbiór informacyjny $I$ a gracze grają strategią $\sigma$ zmodyfikowaną tak, że gracz $i$
podejmuje akcje prowadzące do zbioru informacyjnego $I$ z prawdopodobieństwem $1$. \\\\

\noindent
Wtedy definiujemy:

\begin{align*}
R_i^T(I, a) = \frac{1}{T} \sum\limits_{t=1}^{T} \, \pi_{-i}^{\sigma^t}(I)(u_i(\sigma^t_{I \rightarrow a}, I) - u_i(\sigma^t, I))
\end{align*}
\begin{align*}
R_{i, imm}^T(I) = \max_{a \in A(I)} \, R_i^T(I, a)
\end{align*}

\noindent
Dzięki twierdzeniu z (referencja) wiemy, że $R_i^T \leq \, \sum_{I} \, max(R_{i, imm}^T(I), 0)$. W takim razie
minimalizowanie regretów w zbiorach informacyjnych minimalizuje regret całkowity i prowadzi do znalezienia
dobrej aproksymacji równowagi Nasha. \\

\noindent
Algorytm CFR w kolejnych iteracjach przechodzi drzewo gry i dla każdego zbioru informacyjnego aktualizuje strategię
zgodnie z regułą:

\begin{align*}
\sigma_i^(T+1) (I, a) = \frac{max(R_i^T(I, a), 0)}{\sum\limits_{a' \in A(I)} \, max(R_i^T(I, a'), 0)}
\end{align*}

\noindent
pod warunkiem, że suma w mianowniku jest dodatnia. W przeciwnym wypadku wszystkie akcje w $I$ mają równe prawdopodobieństwo.
Czyli akcja jest wybierana tym częściej im większa strata - regret, wiąże się z nie wybraniem jej.\\\\

\noindent
Całkowity uśredniony regret maleje proporcjonalnie do pierwiastka z liczby iteracji wykonanych przez algorytm CFR. Niestety
liczba stanów gry i zbiorów informacyjnych nawet w dwuosobowej wersji Texas Holdem Poker jest zbyt duża by można było
zastosować algorytm bezpośrednio. W tym celu wprowadza się abstrakcje pełnej wersji gry, przez ograniczenia w licytacji
oraz dzielenie kart na niewielką liczbę grup (koszyków) ze względu na ich siłę. \\

\section{Implementacja Vanilla CFR}

Użyto rekurencyjnej implementacji algorytmu. W danej iteracji algorytmu, mapy $R$, $S$ oraz $\sigma$ przechowują informacje
dla par (zbiór informacyjny, akcja).
\begin{itemize}
\item $R$ : przechowuje sumę regretu po wszystkich dotychczasowych iteracjach algorytmu
\item $\sigma$ : przechowuje prawdopodobieństwo wykonania akcji w zbiorze informacyjnym zgodnie z obecną strategią
\item $S$ : przechowuje sumę strategii z wszystkich dotychczasowych iteracji, ważoną przez $\pi_i^{\sigma^t}$
\end{itemize}

\noindent
Metoda $WalkTree$ przechodzi drzewo gry i przelicza wartości dla $R$ i $S$. Zwraca parę
($\mu_0$, $\mu_1$) oczekiwanych zysków obu graczy w danym stanie gry przy aktualnej strategii. \\\\

%\Call \Comment \If \ElsIf  \Else \EndIf

\begin{algorithmic}
    \Function{WalkTree}{$game$, $[\pi_0^{\sigma}, \pi_1^{\sigma}, \pi_c ]$}
        \If {$game \rightarrow finalState()$}
            \State \Return $game \rightarrow getUtility()$
        \EndIf
        \State $finalUtility \gets 0$ 
        \If {$game \rightarrow randomPlayer()$}
            \For {$(randomAction, randomProb) \, \in \, game \rightarrow distribution()$}
                \State $modGame \gets game \rightarrow makeAction(randomAction)$
                \State $modProb \gets [\pi_0^{\sigma}, \pi_1^{\sigma}, \pi_c \cdot randomProb ]$
                \State $actionUtility \gets \Call{WalkTree}{modGame, modProb}$
                \State $finalUtility \gets finalUtility + actionUtility \cdot randomProb$
            \EndFor
        \Else
            \State $ply \gets game \rightarrow currentPlayer()$
            \State $opp \gets game \rightarrow currentOpponent()$
            \State $I \gets game \rightarrow informationSet()$
            \For {$action \, \in \, game \rightarrow playerActions()$}
                \State $actionProb \gets \sigma(I, action)$
                \State $modGame \gets game \rightarrow makeAction(action)$
                \If {$ply = 0$}
                    \State $modProb \gets [\pi_0^{\sigma} \cdot actionProb, \pi_1^{\sigma}, \pi_c]$
                \Else
                    \State $modProb \gets [\pi_0^{\sigma}, \pi_1^{\sigma} \cdot actionProb, \pi_c]$
                \EndIf
                \State $actionUtility \gets \Call{WalkTree}{modGame, modProb}$
                \State $finalUtility \gets finalUtility + actionUtility \cdot randomProb$
                \State $R(I, action) \gets R(I, action) + actionUtility_{ply} \cdot \pi_{opp}^{\sigma} \cdot \pi_c $
                \State $S(I, action) \gets S(I, action) + actionProb $
            \EndFor
            \For {$action \, \in \, game \rightarrow playerActions()$}
                \State $R(I, action) \gets R(I, action) - finalUtility_{ply} \cdot \pi_{opp}^{\sigma} \cdot \pi_c $
            \EndFor
        \EndIf
    \State \Return finalUtility
    \EndFunction
\end{algorithmic}

$\,$ \\
\noindent
Cały algorytm wygląda następująco: \\

\begin{algorithmic}
    \Function{VanillaCfr}{iterationsNumber}
        \State $R \gets 0$
        \State $S \gets 0$
        \State $\sigma \gets \Call{DefaultStrategy}{}$
        \For {$iterationsNumber$} 
            \State \Call{WalkTree}{newGame(), $[1.0, 1.0, 1.0]$}
            \State $\sigma \gets \Call{RecomputeStrategy}{R}$
        \EndFor
        \State \Return \Call{RecomputeStrategy}{S}
    \EndFunction
\end{algorithmic}

$\,$ \\
\noindent
$DefaultStrategy$ to strategia w której każda akcja jest wykonywana z takim samym prawdopodobieństwem. Metoda
$RecomputeStrategy(R)$ aktualizuje aktualną strategię tak że prawdopodobieństwo zagrania akcji $a$ w zbiorze informacyjnym
$I$ jest proporcjonalne do wartości $R(I, a)$ o ile ta wartość jest nieujemna. Jeśli jest ujemna, prawdopodobieństwo
wynosi $0$. Analogicznie wygląda obliczenie końcowej strategii przy czym patrzymy na wartości $S(I, a)$.

\chapter{Modyfikacja CFR}

\section{Idea}

Drzewo gry pokera jest duże. Nawet przy zastosowaniu bardzo okrojonych abstrakcji, liczba historii przeglądanych w każdej
iteracji algorytmu przekracza milion. Idea modyfikacji algorytmu CFR opiera się na porzuceniu założenia o pełnej pamięci rozgrywki.
W oryginalnej wersji, każdy stan i zbiór informacyjny zawiera całą historię wykonanych w partii zagrań. Algorytm testowany
w tej pracy redukuje liczbę stanów gry przez ignorowanie historii akcji wykonywanych
przez graczy. Stan gry jest opisany przez następujące parametry: \\

\begin{itemize}
\item Aktualny gracz (łącznie z graczem losowym)
\item Aktualna runda (runda licytacji bądź rozdawania kart, jeśli aktualny gracz to gracz losowy)
\item Obecne koszyki obu graczy
\item Liczba odzywek w aktualnej licytacji
\item Proponowana stawka
\item Uzgodniona stawka
\end{itemize}

\noindent
W jednym zbiorze informacyjnym są wszystkie stany, które są tożsame w powyższych parametrach, z wyłączeniem
wiedzy o koszyku przeciwnika. \\

\noindent
Kluczowe dla zmniejszenia złożoności algorytmu było przeformułowanie algorytmu CFR tak, by każdy
stan odwiedzany był tylko raz w jednej iteracji. Dzięki temu złożoność pojedynczej iteracji jest
liniowa względem liczby stanów. Na początku algorytmu tworzony jest graf przejść między
stanami co pozwala uniezależnić iteracje algorytmu od mechaniki gry. Przyspiesza to znacząco
czas obliczeń w pojedynczym stanie.

\section{Tworzenie abstrakcji}

Drzewo gry zmniejszono przez wprowadzenie ograniczeń w licytacji oraz podział układów kart na koszyki.
W każdej rundzie licytacji gracze mają prawo do jednokrotnego podbicia stawki. Łącznie dostępne są cztery akcje:

\begin{itemize}
\item \textbf{fold} - zrezygnowanie z udziału w rozgrywce.
\item \textbf{call} - zgodzenie się na obecną stawkę.
\item \textbf{raise} - zaproponowanie stawki dwukrotnie większej niż obecna
\item \textbf{all in} - zaproponowanie maksymalnej stawki
\end{itemize}

\noindent
Niektóre akcje są niedostępne jeżeli nie mają strategicznego sensu, np \textbf{fold} w przypadku gdy
proponowana stawka nie jest wyższa niż stawka, na którą gracz już się zgodził. \\

\noindent
W celu podzielenia układów na koszyki, układy z jednej rundy są sortowane po wartości $EHS$. Jeżeli mają być podzielone na
$n$ koszyków, to są dzielone tak, by w każdym koszyku znalazła się podobna liczba układów (czyli $\frac{1}{n}$ wszystkich układów). \\

\noindent
Na potrzebę wyliczania strategii liczone są prawdopodobieństwa przejść między parami koszyków. Czyli np dla każdej kombinacji
trójek kart pojawiąjących się na stole na flopie, liczone jest prawdopodobieństwo zmiany koszyka o numerze $A$ z pierwszej
rundy na koszyk $B$ w drugiej rundzie dla każdej takiej pary $(A, B)$. Dodatkowo liczone są rozkłady koszyków
w każdej rundzie, zależne od koszyków z poprzedniej rundy. \\

\noindent
Wyliczenie wartości $EHS$ dla wszystkich możliwych układów wymaga przejrzenia wszystkich możliwych kombinacji 9 kart (2 kart gracza, 2 przeciwnika
oraz 5 kart na stole). Jest to bardzo wymagające obliczeniowo. By skrócić obliczenia, EHS jest wyliczane jedynie dla niektórych układów
kart gracza. Jest to oparte na obserwacji że niektóre układy powinny mieć taki sam $EHS$. Np $EHS$ pary As Kier i As Karo powinien być taki
sam jak $EHS$ pary As Kier, As Trefl albo As Pik, As Karo. 

\begin{align*}
(A\heartsuit, A\spadesuit) = (A\heartsuit, A\diamondsuit) = (A\heartsuit, A\clubsuit) = (A\spadesuit, A\diamondsuit) =
(A\spadesuit, A\clubsuit) = (A\diamondsuit, A\clubsuit)
\end{align*}

\noindent
W ogólności, wyliczając $EHS$ układów operuję nie na pełnym zbiorze $52$ kart a na zbiorze $13$ figur. Dany układ figur
może występować w kilku wersjach uwzględniających kolory kart. Para tych samych figur jest zawsze różnokolorowa ale w 
parze różnych figur mogą one występować w tym samym kolorze bądź w różnych kolorach i wpływa to na $EHS$ takich układów.

\begin{align*}
EHS(A\heartsuit, K\heartsuit) \neq EHS(A\heartsuit, K\spadesuit)
\end{align*}

\noindent
Stosując tę koncepcję wprowadzono klasy abstrakcji dla układów kart. Układy kart dochodzące w kolejnych rundach są traktowane
osobno. Poniżej typy układów dla poszczególnych rund, napis $Fnx$ oznacza figurę numer $n$ w kolorze $x$. 

\noindent
\textbf{Pre-flop}:
\begin{itemize}
\item (F1a, F1b)
\item (F1a, F2a)
\item (F1a, F2b)
\end{itemize}

\noindent
\textbf{Flop}:
\begin{itemize}
\item (F1a, F1b, F1c)
\item (F1a, F1b, F2a)
\item (F1a, F1b, F2c)
\item (F1a, F2a, F3a)
\item (F1a, F2a, F3b)
\item (F1a, F2b, F3c)
\end{itemize}

\noindent
Dla rund Turn i River w których dochodzi po jednej karcie, każda klasa abstrakcji to czwórka kart o tej samej figurze. \\

\noindent
W celu wyliczenia wartości $HS$ dla układu, przeglądane są wszystkie możliwe pary kart u przeciwnika i liczony jest procent
przypadków gdy siła układu jest większa niż siła kart przeciwnika poszerzonych o karty ze stołu występujące w układzie.
By wyliczyć potencjał układu z rund $1$, $2$, $3$ (dla rundy $4$ liczenie potencjału nie ma sensu) przeglądane są wszystkie
możliwe kombinacje następnych kart na stole. Jeżeli po dodaniu następnych kart, układ zmienił się z przegrywającego w
wygrywający, rośnie wartość $Ppot$. W odwrotnej sytuacj rośnie $Npot$.



\section{Zmodyfikowany CFR}

Zmodyfikowany algorytm CFR redukuje liczbę stanów gry przez ignorowanie historii akcji wykonywanych
przez graczy. Stan gry jest opisany przez następujące parametry: \\
\begin{itemize}
\item Aktualny gracz (łącznie z graczem losowym)
\item Aktualna runda (runda licytacji bądź rozdawania kart, jeśli aktualny gracz to gracz losowy)
\item Obecne koszyki obu graczy
\item Liczba odzywek w aktualnej licytacji
\item Proponowana stawka
\item Uzgodniona stawka
\end{itemize}

\noindent
Algorytm zakłada że są to informacje wystarczające do podjęcia decyzji o wykonywanym ruchu.
Ważną modyfikacją jest utożsamienie stanów gry i zbiorów informacyjnych. Algorytm liczy strategię
tak jakby graczom była dostępna informacja o koszyku przeciwnika. Czyli abstrakcja gry jest grą
z pełną informacją. Wymusza to zmianę sposobu korzystania z wyliczonej strategii. W normalnej wersji
CFR, strategia jest określona dla zbioru informacyjnego gracza. W zmodyfikowanej wersji, gracz
nie jest pewny w którym stanie gry się znajduje, ponieważ nie wie jaki koszyk ma jego przeciwnik.
Zamiast tego, wylicza oczekiwany rozkład koszyków przeciwnika zgodnie z jego zagraniami i kartami
widocznymi na stole. Następnie stosuje strategię, która jest ważoną sumą strategii wyliczonych
przez algorytm dla każdego możliwego koszyka przeciwnika. Wagami są prawdopodobieństwa że
przeciwnik znajduje się w danym koszyku. \\

\noindent
Zauważmy, że złożoność jednego przebiegu metody $WalkTree$ w oryginalnym CFR jest liniowa w stosunku
do rozmiaru drzewa gry. Przy dużej liczbie koszyków drzewo gry jest bardzo duże i uniemożliwia
wykonanie potrzebnej liczby iteracji algorytmu w rozsądnym czasie. Autor pracy zmodyfikował algorytm
Vanilla Cfr tak by wykonanie jednej iteracji miało złożoność liniową względem liczby stanów gry.
W sytuacji gdy stan gry nie zawiera informacji o historii rozgrywki liczba stanów jest znacząco
mniejsza od rozmiaru drzewa gry co pozwala na wykonanie znacznie większej liczby iteracji algorytmu. \\

\noindent
Dodatkową optymalizacją jest zlikwidowanie operacji wykonywanych przy każdym ruchu przez abstrakcję gry.
Na początku algorytmu obliczany jest graf przejść między stanami gry. Wierzchołkami są stany gry. Krawędź
skierowana między wierzchołkiem/stanem $s_1$ a stanem $s_2$ istnieje jeśli istnieje akcja $a$ w stanie
$s_1$, która prowadzi do stanu $s_2$. Taka krawędź jest etykietowana akcją $a$. Jeśli była to akcja
gracza losowego, dołączona jest informacja o prawdopodobieństwie zajścia tej akcji. W stanach końcowych
zachowana jest informacja o zyskach obu graczy. Dzieki temu iteracje algorytmu są wyizolowane od samej
mechaniki gry. \\

\noindent
Wspomniany wyżej graf stanów jest budowany przy użyciu algorytmu DFS. W każdym nowo odwiedzanym stanie
wyliczany jest jego identyfikator na podstawie aktualnych wartości parametrów. Dodatkowo dodawane
są krawędzie prowadzące do sąsiednich stanów, a w stanach końcowych zapisywana jest informacja o
zyskach graczy. Zauważmy, że w tak utworzonym grafie nie występują cykle. Po utworzeniu, wierzchołki
są sortowane topologicznie co ułatwi potem wykonywanie iteracji. \\

\noindent
W każdej iteracji wykonywane są dwie metody: $computeProbs$ oraz $modWalkTree$. Pierwsza oblicza dla każdego stanu $s$
wartości $\pi_0^{\sigma}(s)$, $\pi_1^{\sigma}(s)$, $\pi_0^{\sigma}(s) \cdot \pi_c(s)$ oraz $\pi_1^{\sigma}(s) \cdot \pi_c(s)$
dla aktualnej strategii $\sigma$. Niech $H(s)$ oznacza zbiór historii $h$, których rezultatem jest stan $s$. Wtedy
\begin{align*}
\pi_i^{\sigma}(s) = \sum\limits_{h \in H(s)} \, \pi_i^{\sigma}(h)
\end{align*}
\begin{align*}
\pi_i^{\sigma}(s) \cdot \pi_c(s) = \sum\limits_{h \in H(s)} \, \pi_i^{\sigma}(h) \cdot \pi_c(h)
\end{align*}

\noindent
Zauważmy, że dla każdej historii $h \in H(s)$ zysk graczy jest taki sam. W takim razie można zamienić instrukcję
\begin{algorithmic}
    \State $R(I, action) \gets R(I, action) + actionUtility_{ply}(h) \cdot \pi_{opp}^{\sigma}(h) \cdot \pi_c(h) $
\end{algorithmic}

\noindent
wykonywaną dla każdej historii $h \in H(s)$ na instrukcję

\begin{algorithmic}
    \State $R(I, action) \gets R(I, action) + actionUtility_{ply}(s) \cdot \pi_{opp}^{\sigma}(s) \cdot \pi_c(s) $
\end{algorithmic}

\noindent
wykonywaną jednokrotnie w stanie $s$. Zauważmy, że zachodzi \\

\begin{align*}
\pi_{p}^{\sigma}(s) = \sum\limits_{s' : E(s', s)} \pi_{p}^{\sigma}(s') \cdot prob_{p}(E(s', s))
\end{align*}
\begin{align*}
\pi_p^{\sigma}(s) \cdot \pi_c(s) = \sum\limits_{s' : E(s', s)} \pi_{p}^{\sigma}(s') \pi_c(s') \cdot prob_p(E(s', s)) \cdot prob_c(E(s', s))
\end{align*}

gdzie $E(s_1, s_2)$ zachodzi gdy istnieje krawędź z $s_1$ do $s_2$ a $prob_{i}(E(s_1, s_2))$ oznacza prawdopodobieństwo przejścia ze stanu
$s_1$ do $s_2$ jeżeli akcję wykonuje gracz $i$. W przeciwnym przypadku $prob_{i}(E(s_1, s_2)) = 1$. Metoda $computeProbs$ wykonuje algorytm
BFS, który przechodzi stany w porządku topologicznym i oblicza powyższe wartości. \\

\noindent
Metoda $modWalkTree$ przechodzi rekurencyjnie graf stanów, obliczając oczekiwany zysk graczy
w każdym stanie przy obecnej strategii. Dodatkowo aktualizuje mapy $R$ oraz $S$ analogicznie do metody $WalkTree$ ze
zwykłej wersji CFR.

\chapter{Wyniki eksperymentalne}

\chapter{Podsumowanie}

\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}
\bibitem[1]{exploit} B. Hoehn, F. Southey, V.Bulitko and R.C. Holte, $\;\;\;$
"Effective Short-Term Opponent Exploitation in Simplified Poker" $\;\;\;$ Mach. Learn., 2009. 74(2)
\bibitem[2]{monte-carlo} G.V.D. Broeck, K. Driessens and J.Ramon, $\;\;\;$
"Monte-Carlo Tree Search in Poker using Expected Reward Distributions" $\;\;\;$
ACML 2009. LNCS (LNAI), vol. 5828
\end{thebibliography}

\end{document}
